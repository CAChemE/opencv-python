{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "72a7c411-cf21-4d47-a9b9-f5db1f8c9c60"
    }
   },
   "source": [
    "# CURSO DE INTRODUCCIÓN A OPENCV Y PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7cd741bd-a4ab-4824-9dcd-3708cfbad4e3"
    }
   },
   "source": [
    "¿Quién soy?\n",
    "\n",
    "**Rubén Crespo Cano**\n",
    "\n",
    "Estudios:\n",
    "* Ingeniería en Informática [Universidad de Alicante] (2006 - 2012)\n",
    "* Máster en Ingeniería de Telecomunicación [Universidad de Alicante] (2012 - 2015)\n",
    "* Doctorado en Informática [Universidad de Alicante] (2016 - Presente)\n",
    "\n",
    "Trabajo:\n",
    "* Ingeniero de software en Everilion (http://www.everilion.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a32ecb3d-7126-45aa-b39c-f245fd0245a4"
    }
   },
   "source": [
    "# 0. Introducción\n",
    "\n",
    "\n",
    "## OpenCV\n",
    "OpenCV es una biblioteca de visión artificial de código libre, escrita en C++, originalmente desarrollada por Gary Bradsky en Intel. Fue construida para proporcionar una infrastructura común para aplicaciones de visión por computador. \n",
    "\n",
    "La librería contiene más de 2500 algoritmos optimizados, entre los que se incluyen algoritmos clásicos y algoritmos del estado del arte de los campos de visión por computador y aprendizaje automático.\n",
    "\n",
    "Características principales:\n",
    "* Licencia BSD.\n",
    "* Interfaces: C++, C, Python, Java y MATLAB.\n",
    "* Sistemas Operativos: Windows, GNU/Linux, Android y Mac OS.\n",
    "* Soporte CUDA y OpenCL.\n",
    "\n",
    "URL: http://www.opencv.org\n",
    "\n",
    "\n",
    "## Python\n",
    "Python es un lenguaje de programación creado por Guido van Rossum a principios de los años 90 cuyo nombre está inspirado en el grupo de cómicos ingleses *Monty Python*. Es un lenguaje similar a Perl, pero con una sintaxis muy limpia y que favorece un código legible. Python es un lenguaje de propósito general que ha llegado a ser muy popular en muy poco tiempo debido a su simplicidad y legibilidad, ya que permite a el/la programador/a expresar ideas en muy pocas líneas de código sin reducir la legibilidad.\n",
    "\n",
    "Se trata de un lenguaje interpretado o de script, con tipado dinámico, fuertemente tipado, multiplataforma y orientado a objetos.\n",
    "\n",
    "Si se compara con lenguajes como C/C++, Python es generalmente más lento. Dicho esto, Python puede ser fácimente extendido mediante código C/C++, lo que permite escribir código fuente computacionalmente intensivo en C/C++ y crear envolturas en Python que puedan ser usadas por módulos de Python. Esto proporciona dos ventajas: primero, el código es tan rápido como el código original C/C++ y segundo, es más fácil desarrollar en Python que en C/C++.\n",
    "\n",
    "URL: https://www.python.org/\n",
    "\n",
    "\n",
    "## OpenCV-Python\n",
    "\n",
    "OpenCV-Python es el API de OpenCV para Python, donde se combinan las mejores cualidades del API C++ de OpenCV con el lenguaje de programación Python, diseñada para resolver problemas de visión por computador. \n",
    "\n",
    "OpenCV-Python hace uso de Numpy, que es una librería altamente optimizada para operaciones de cálculo numérico con una sintaxis similar a la de MATLAB. Todas las estructuras array son convertidas a Numpy arrays. Esto permite la integración con otras librerías que también hacen uso de Numpy, tales como SciPy o Matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c46893e7-63cc-4cd0-a5fe-85a94f724611"
    }
   },
   "source": [
    "# 1. Instalación\n",
    "\n",
    "## Instalación en Windows\n",
    "* http://docs.opencv.org/3.1.0/d5/de5/tutorial_py_setup_in_windows.html\n",
    "\n",
    "\n",
    "## Instalación en GNU/Linux\n",
    "* http://docs.opencv.org/3.1.0/dd/dd5/tutorial_py_setup_in_fedora.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ce9a3de4-cd6b-4df8-bfb2-9e62e1243c7e"
    }
   },
   "source": [
    "# 2. Manejo de ficheros, cámaras e interfaces gráficas de usuario\n",
    "\n",
    "La gran mayoría de aplicaciones que se desarrollan con OpenCV necesitan como entrada una o varias imágenes, pero también puede ser que esas imágenes se presenten en forma de vídeo. Además, también es bastante probable que las aplicaciones necesiten generar como salida del programa una nueva imágen. \n",
    "\n",
    "\n",
    "## Lectura y escritura de imágenes\n",
    "Hay que utilizar la función **cv2.imread()** para leer una imágen. La imágen debe estar en el directorio de trabajo o debe proporcionarse la ruta absoluta de la imagen.\n",
    "\n",
    "El segundo argumento es un *flag* que especifica la forma en la que la imagen debe ser leída.\n",
    "* cv2.IMREAD_COLOR: Carga la imagen a color. Si la imagen posee transparencias serán desechadas. Es el *flag* por defecto.\n",
    "* cv2.IMREAD_GRAYSCALE: Carga la imagen en modo escala de grises.\n",
    "* cv2.IMREAD_UNCHANGED: Carla la imagen incluyendo el canal *alpha*.\n",
    "\n",
    "Para poder escribir/guardar una nueva imagen, hay que utilizar la función **cv2.imwrite()**.\n",
    "\n",
    "\n",
    "**Ejemplo 1**. Cargar una imagen y guardarla con otro nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "8751a1a2-8b04-4589-a932-4225e954220f"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load\n",
    "image_path = 'images/rabbit.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Save copy as png\n",
    "image_copy_path = 'images/rabbit-copy.png'\n",
    "cv2.imwrite(image_copy_path, image)\n",
    "\n",
    "# Load copy\n",
    "image_copy = cv2.imread(image_copy_path)\n",
    "# Show\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Copy', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5a74133a-56c5-4d91-b13b-33ab05d996ce"
    }
   },
   "source": [
    "\n",
    "**Ejercicio 1**. Cargar una imagen y guardar una copia en blanco y negro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "53036ea1-9525-4153-ba9b-11f2494d8696"
    }
   },
   "outputs": [],
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6fcb7aee-2b44-4099-bb62-88ed8d1a557c"
    }
   },
   "source": [
    "## Conversión entre imágenes y *raw bytes*\n",
    "Conceptualmente, un byte es un entero que se encuentra en el rango [0, 255]. En las aplicaciones actuales, un píxel es representado normalmente por un byte por canal, aunque también pueden haber otras representaciones.\n",
    "\n",
    "Una imagen OpenCV es un array 2D o 3D de tipo **numpy.array**. Una imagen en escala de grises de 8 bits es un array 2D que contiene valores para cada byte. Una imagen a color RGB es un array 3D, que también contiene valores para cada byte. Es posible acceder a esos valores utilizando una expresión como la siguiente:\n",
    "* image[0, 0] o image[0, 0, 0]\n",
    "\n",
    "El primer índice representa la coordenada *y* (fila), siendo el 0 el valor que está más arriba. El segundo índice representa la coordenada *x* (columna), siendo el valor 0 el que está más a la izquierda. El tercer índice (en imágenes RGB) representa el canal de color.\n",
    "\n",
    "Por ejemplo, una imagen en escala de grises con un píxel blanco en la esquina superior izquierda, image[0, 0] sería 255. Para una imagen RGB con un píxel de color azul en la esquina superior izquierda, image[0, 0] sería [255, 0, 0].\n",
    "\n",
    "TODO\n",
    "\n",
    "\n",
    "## Introducción al manejo de vídeos\n",
    "\n",
    "Para capturar un vídeo, es necesario crear un objeto de tipo **VideoCapture**. Su argumento puede ser tanto el índice del dispositivo o el nombre del fichero.\n",
    "\n",
    "El índice del dispositivo es el número que identifica qué camara capturar. Como normalmente sólo suele haber una cámara conectada, se suele utilizar el identificador 0 para capturar de ella.\n",
    "\n",
    "El método **cap.read()** devuelve un valor booleano (True/False). Si el *frame* se leyó correctamente, devolverá True. De esta forma, se puede comprobar cuándo se ha llegado al final de la lectura del vídeo comprobando este parámetro. \n",
    "\n",
    "A veces, el objeto **VideoCapture** puede no haber logrado la inicialización de la captura correctamente. Por ello, es mejor comprobar si se ha inicializado o no a través del método **cap.isOpened()**. Si el resultado es True es que sí se ha podido abrir la captura.\n",
    "\n",
    "\n",
    "**Ejemplo 2**. Cargar y reproducir un vídeo en escala de grises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "video_file = 'videos/roller-coaster.mp4'\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        # Operations on the frame\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame', gray)\n",
    "    \n",
    "        # Exit?\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, también es posible acceder a algunas de las propiedades del vídeo utilizando el método **cap.get(prop_id)** donde **prop_id** es un número [0, 18] que denota una propiedad del vídeo. Por último, hay que destacar que algunos de esos valores pueden ser modificados mediante el método **cap.set(prop_id, value)**. En el siguiente enlace están descritas todas las propiedades:\n",
    "* http://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get\n",
    "\n",
    "\n",
    "**Ejemplo 3**. Mostrar los FPS del vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "video_file = 'videos/roller-coaster.mp4'\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 1\n",
    "color = (255,255,255)\n",
    "thickness = 1\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # Text position\n",
    "        height = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT))\n",
    "        position = (50, height - 50)\n",
    "        \n",
    "        # Frames per second\n",
    "        fps = \"{0:.2f}\".format(cap.get(cv2.cv.CV_CAP_PROP_FPS))\n",
    "        text = \"FPS: \" + fps\n",
    "        \n",
    "        # Put text\n",
    "        cv2.putText(frame, text, position, font, font_scale, color, thickness)\n",
    "\n",
    "        # Display\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "        \n",
    "        # Exit?\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Ejercicio 2**. Descargar un vídeo de https://videos.pexels.com/video-license y mostrar las propiedades más relevantes sobre el propio vídeo mientras se reproduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captura de vídeo desde la *webcam* \n",
    "\n",
    "El índice del dispositivo es el número que identifica qué camara capturar. Como normalmente sólo suele haber una cámara conectada, se suele utilizar el identificador 0 para capturar de ella.\n",
    "\n",
    "**Ejemplo 4**. Captura de vídeo desde la *webcam* y operaciones de inversión de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "webcam_id = 0\n",
    "cap = cv2.VideoCapture(webcam_id)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # Operations on the frame\n",
    "        v_frame = cv2.flip(frame, 1)\n",
    "        h_frame = cv2.flip(frame, 0)\n",
    "        \n",
    "        # Display\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "        cv2.imshow(\"Vertical flip\", v_frame)\n",
    "        cv2.imshow(\"Horizontal flip\", h_frame)\n",
    "\n",
    "        # Exit?\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ab4ce54-49ec-41a4-ab3f-33ee8d8cfbcb"
    }
   },
   "source": [
    "# 3. Filtrado y suavizado de imágenes\n",
    "\n",
    "## 3.1. Filtrado de imágenes. Convolución 2D\n",
    "\n",
    "Las imágenes pueden ser filtradas por varios tipos de filtros, tales como filtros *paso-bajo*, filtros *paso-alto*, etc.\n",
    "\n",
    "* Un filtro *paso-bajo* atenúa las frecuencias altas y mantiene sin variaciones las frecuencias bajas. El resultado en el dominio espacial es equivalente al de un filtro de suavizado, donde las altas frecuencias que son filtradas se corresponden con los cambios fuertes de intensidad. Consigue reducir el ruido suavizando las transiciones existentes.\n",
    "\n",
    "* Un filtro *paso-alto* atenúa las frecuencias bajas manteniendo invariables las frecuencias altas. Puesto que las altas frecuencias corresponden en las imágenes a cambios bruscos de densidad, este tipo de filtros es usado en la detección de bordes en el dominio espacial, ya que estos contienen gran cantidad de dichas frecuencias. Refuerza los contrastes que se encuentran en la imagen.\n",
    "\n",
    "OpenCV proporciona la función **cv2.filter2D()** para realizar la convolución de una imagen con un *kernel* determinado. Por ejemplo, un *kernel* de tamaño 3x3 para un filtro de promedio se puede definir de la siguiente forma:\n",
    "\n",
    "$K = \\frac{1}{9} \\left[ \\begin{array}{ccc}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 \\\\ \\end{array} \\right]$\n",
    "\n",
    "El procedimiento de filtrado es el siguiente: para cada píxel de la imagen, una ventana de tamaño 3x3 es centrada en él, sumándose los valores y dividiéndose entre 9. Esto equivale a realizar la media de los valores de los píxeles de dentro de la ventana. Esta operación se realiza para cada uno de los píxeles de la imagen.\n",
    "\n",
    "En cuanto a la función **cv2.filter2D()** los parámetros obligatorios son los siguientes:\n",
    "* src – input image.\n",
    "* dst – output image of the same size and the same number of channels as src.\n",
    "* ddepth – desired depth of the destination image; if it is negative, it will be the same as src.depth().\n",
    "\n",
    "\n",
    "\n",
    "**Ejemplo 5**. Filtrado de imagen con un kernel 3x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image_file = 'images/rabbit.jpg'\n",
    "img = cv2.imread(image_file)\n",
    "\n",
    "kernel = np.ones((3, 3), np.float32) / 9\n",
    "dst = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
    "\n",
    "# Show\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Filtered', dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3**. Descargar una imagen y aplicar un filtrado 2D con un *kernel* de tamaño 5x5 ponderado. Probar a cambiar los distintos valores del *kernel*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Suavizado de imágenes\n",
    "\n",
    "El suavizado de imágenes se logra realizando la convolución de la imagen con un filtro *paso-bajo* y suele utilizarse para la reducción y/o eliminación del ruido, ya que se elimina el contenido de altas frecuencias. OpenCV proporciona varias técnicas para el suavizado de imágenes. A continuación veremos varias de ellas.\n",
    "\n",
    "### 3.2.1. Promedio\n",
    "Esta operación se realiza mediante la convolución de la imagen con un filtro normalizado. Simplemente calcula la media de los píxeles que están bajo el área del *kernel* y reemplaza el valor del elemento central. Esta operación se realiza mediante la función **cv2.blur()**. En la llamada, debe especificarse el tamaño del *kernel*, tanto el ancho como el alto.\n",
    "\n",
    "**Ejemplo 6**. Filtrado de imagen: promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load image\n",
    "image_path = 'images/sunset.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Blur\n",
    "k = 5\n",
    "blur = cv2.blur(image, (k, k))\n",
    "\n",
    "# Show\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Filtered', blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 4**. Descargar una imagen con muchos colores. Cambiar el tamaño del *kernel* y comprobar qué ocurre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ejercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Filtro Gaussiano\n",
    "Si queremos utilizar un kernel Gaussiano, deberemos utilizar la función **cv2.GaussianBlur()**. Al igual que en el caso anterior, debemos especificar el ancho y alto del kernel, que debe ser un número impar positivo. Además, también debe especificarse la desviación estándar en las direcciones *X* e *Y*, a través de los parámetros *sigmaX* y *sigmaY* respectivamente. Si sólo se especifica el valor para el parámetro *sigmaX*, la función asigna el mismo valor para el parámetro *sigmaY*.\n",
    "\n",
    "**Ejemplo 7**. Filtrado de imagen: filtro Gaussiano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load image\n",
    "image_path = 'images/sunset.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Gaussian blur\n",
    "k = 5\n",
    "sigma = 0\n",
    "blur = cv2.GaussianBlur(image, (k, k), sigma)\n",
    "\n",
    "# Show\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Filtered', blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 5**. Cambiar el tamaño del *kernel* y el valor del parámetro *sigma* y comprobar qué ocurre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las razones por las que los filtros de tipo Gaussiano son tan importantes es que son muy efectivos para eliminar ruido Gaussiano de la imagen.\n",
    "\n",
    "**Ejemplo 8**. Filtrado de imagen: filtro Gaussiano sobre imagen con mucho ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load image\n",
    "image_path = 'images/lena_noise.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Gaussian blur\n",
    "k = 5\n",
    "sigma = 0\n",
    "blur = cv2.GaussianBlur(image, (k, k), sigma)\n",
    "\n",
    "# Show\n",
    "cv2.imshow('Original Lena with noise', image)\n",
    "cv2.imshow('Filtered Lena', blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 6**. Buscar una imagen con ruido y aplicar filtro Gaussiano para reducir el nivel de ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ejercicio 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Mediana\n",
    "El filtro mediana se aplica mediante la función **cv2.medianBlur()**. En él, se calcula la mediana de todos los píxeles que están bajo el área del *kernel* y el elemento central se sustituye con el valor de la mediana. El valor para el tamaño del *kernel* debe ser un número impar positivo.\n",
    "\n",
    "Este filtro es muy efectivo para eliminar el ruido impulsional, llamado \"sal y pimienta\". \n",
    "* https://en.wikipedia.org/wiki/Salt-and-pepper_noise\n",
    "\n",
    "\n",
    "**Ejemplo 9**. Filtrado de imagen: filtro mediana sobre imagen con ruido de tipo \"sal y pimienta\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load image\n",
    "image_path = 'images/salt_pepper_noise.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Gaussian blur\n",
    "k = 5\n",
    "blur = cv2.medianBlur(image, k)\n",
    "\n",
    "# Show\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Filtered', blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 7**. Buscar una imagen con ruido impulsional (\"sal y pimienta\") y aplicar el filtro mediana para reducir el nivel de ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ejercicio 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Gradientes\n",
    "\n",
    "En este apartado vamos a enseñar varios filtros *paso-alto* que nos permitirán filtrar las imágenes para extraer bordes y gradientes.\n",
    "\n",
    "## 4.1. Sobel\n",
    "El operador Sobel, también conocido como el operador Sobel–Feldman, realiza un gradiente espacial 2-D sobre una imagen y de esta forma enfatiza las regiones con altras frecuencias espaciales, que se corresponden con bordes. \n",
    "\n",
    "El operador utiliza dos *kernels* de tamaño 3x3 los cuales son convolucionados con la imagen original para calcular aproximaciones de las derivativas, una para cambios en el eje horizontal y otra para cambios en el eje vertical.\n",
    "\n",
    "*Kernels* de convolución Sobel:\n",
    "\n",
    "$Gx = \\left[ \\begin{array}{ccc}\n",
    "-1 & 0 & +1 \\\\\n",
    "-2 & 0 & +2 \\\\\n",
    "-1 & 0 & +1 \\\\ \\end{array} \\right]$\n",
    "\n",
    "$Gy = \\left[ \\begin{array}{ccc}\n",
    "+1 & +2 & +1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "-1 & -2 & -1 \\\\ \\end{array} \\right]$\n",
    "\n",
    "Estos *kernels* están diseñados para responder ante ejes verticales y horizontales. Pueden ser aplicados de forma separada a la imagen de entrada para producir mediciones separadas, o por el contrario, pueden ser combinados para encontrar y delimitar ejes en ambas direcciones.\n",
    "\n",
    "La función que realiza este filtrado es **cv2.Sobel()**. Se puede especificar la dirección de los gradientes, vertical u horizontal, mediante los argumentos *xorder* e *yorder* respectivamente. Además, también se puede especificar el tamaño del *kernel* meidnte el argumento *ksize*.\n",
    "\n",
    "**Ejemplo 10**. Filtros de Sobel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread('images/sudoku.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Sobel\n",
    "k = 3\n",
    "sobelx = cv2.Sobel(image, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=k)\n",
    "sobely = cv2.Sobel(image, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=k)\n",
    "\n",
    "# Show\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Sobel X', sobelx)\n",
    "cv2.imshow('Sobel Y', sobely)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Laplacian\n",
    "\n",
    "El operador Laplacian es una medida isotrópica 2-D de la segunda derivada espacial de una imagen. Aplicar un filtro Laplacian sobre una imagen consigue resaltar las regiones en las que se producen cambios bruscos de intensidad, y es por tanto utilizada para detección de bordes. Normalmente, el filtro Laplacian es aplicado sobre una imagen que ha sido previamente filtrada con un filtro Gaussiano para poder reducir la sensibilidad ante ruido.\n",
    "\n",
    "La función que proporciona OpenCV para aplicar un filtro Laplacian es **cv2.Laplacian()**. Los argumentos obligatorios son la imagen de entrada y la profundidad de la imagen de salida.\n",
    "\n",
    "**Ejercicio 8**. Buscar una imagen (con ruido) de edificios y aplicar el filtro Laplacian sobre la imagen sin filtrar y sobre la imagen filtrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ejercicio 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Canny edge detector\n",
    "\n",
    "El algoritmo de Canny es un operador desarrollado por John F. Canny en 1986 que utiliza un algoritmo de múltiples etapas para detectar una amplia gama de bordes en imágenes.\n",
    "\n",
    "Las etapas del algoritmo son las siguientes:\n",
    "\n",
    "1. **Reducción de ruido**. Debido a que la detección de bordes puede verse afectada por el ruido que contenga la imagen, el primer paso es la eliminación del ruido en la imagen mediante un filtro Gaussiano con un *kernel* 5x5.\n",
    "\n",
    "2. **Búsqueda de gradientes de intensidad**. El borde de una imagen puede apuntar a diferentes direcciones, por lo que el algoritmo de Canny utiliza cuatro filtros para detectar los bordes en las direcciones horizontal, vertical y diagonales.\n",
    "\n",
    "3. **Supresión de no máximos**. Después de obtener las magnitudes de gradiente y dirección, se realiza un análisis de toda la imagen para eliminar los píxeles no deseados que no constituyan ningún eje. Para ello, cada píxel es examinado comprobando si es un máximo local en su vecindario en la dirección del gradiente. Si el píxel no es un máximo local, se establece a cero. En resumen, el resultado que se obtiene es una imagen binaria con \"ejes estrechos\".\n",
    "<img src=\"images/nms.jpg\">\n",
    "\n",
    "4. **Umbrales**. En esta última etapa del algoritmo, se decide sobre todos los ejes obtenidos cuáles de ellos son realmente ejes y cuáles de ellos no. Para ello, se establecen dos valores umbral, *minVal* y *maxVal*. Todos los ejes con una intensidad de gradiente mayor que el valor umbral *maxVal* se consideran de forma segura como ejes. Todos los ejes con una intensidad de gradiente menor que el valor umbral *minVal* se consideran de forma segura como no ejes, y por tanto, son descartados. Aquellos que se encuentran entre los valores *minVal* y *maxVal* son clasificados dependiendo de su conexión. Si están conetados a los píxeles con valor mayor a *maxVal* son considerados parte de los ejes. En cualquier otro caso son descartados.\n",
    "<img src=\"images/hysteresis.jpg\">\n",
    "\n",
    "\n",
    "OpenCV proporciona la implementación del detector de bordes Canny mediante la función **cv2.Canny()**. El primer argumento de la función es la imagen. El segudo y el tercer argumento son los valores de los parámetros *minVal* y *maxVal* respectivamente. El cuarto argumento es el valor para establecer el tamaño del *kernel* del fintro Sobel (por defecto tiene el valor 3).\n",
    "\n",
    "**Ejemplo 11**. Detector de bordes Canny a través de la *webcam*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "webcam_id = 0\n",
    "cap = cv2.VideoCapture(webcam_id)\n",
    "\n",
    "# Cany edge detector thresholds\n",
    "threshold_one = 50\n",
    "threshold_two = 150\n",
    "aperture_size = 3\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # Operations on the frame\n",
    "        edges = cv2.Canny(frame, threshold_one, threshold_two, aperture_size)\n",
    "        \n",
    "        # Display\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "        cv2.imshow(\"Canny edge detection\", edges)\n",
    "\n",
    "        # Exit?\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 9**. Buscar una imagen y aplicar el filtro Canny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ejercicio 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "61f02149-01e2-4d54-9bd1-d7dd846badcc"
    }
   },
   "source": [
    "# Referencias\n",
    "* http://www.wikipedia.com\n",
    "* https://commons.wikimedia.org\n",
    "* http://www.opencv.org\n",
    "* http://www.python.org\n",
    "* https://realpython.com\n",
    "* http://homepages.inf.ed.ac.uk/rbf/HIPR2/hipr_top.htm\n",
    "* Python para todos. Raúl González Duque.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {
    "22e9b66f-fd2e-42df-99cd-e4e0f21ad779": {
     "id": "22e9b66f-fd2e-42df-99cd-e4e0f21ad779",
     "prev": "477fec80-ffd1-42e0-8484-27ff3f4898c8",
     "regions": {
      "03918df8-3e2c-4ae3-9a27-26c1a2cbf0c5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4ab4ce54-49ec-41a4-ab3f-33ee8d8cfbcb",
        "part": "whole"
       },
       "id": "03918df8-3e2c-4ae3-9a27-26c1a2cbf0c5"
      }
     }
    },
    "24557e4b-ec5d-43f2-bf81-bab6bc0cef90": {
     "id": "24557e4b-ec5d-43f2-bf81-bab6bc0cef90",
     "prev": null,
     "regions": {
      "0366134a-f9e8-4ee3-b881-81f69d10a306": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "72a7c411-cf21-4d47-a9b9-f5db1f8c9c60",
        "part": "whole"
       },
       "id": "0366134a-f9e8-4ee3-b881-81f69d10a306"
      }
     }
    },
    "3c3beb2d-9d61-4d5a-8994-02de7df212c0": {
     "id": "3c3beb2d-9d61-4d5a-8994-02de7df212c0",
     "prev": "96a74b97-5cea-4633-9068-6187a1db86f2",
     "regions": {
      "9d1e269f-6790-477c-b410-b24d3bd25260": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c46893e7-63cc-4cd0-a5fe-85a94f724611",
        "part": "whole"
       },
       "id": "9d1e269f-6790-477c-b410-b24d3bd25260"
      }
     }
    },
    "477fec80-ffd1-42e0-8484-27ff3f4898c8": {
     "id": "477fec80-ffd1-42e0-8484-27ff3f4898c8",
     "prev": "b0c0a833-6909-4699-9d26-99772e73cf0f",
     "regions": {
      "90449ea6-5afc-49c7-a0c0-f96385d5f3b1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6fcb7aee-2b44-4099-bb62-88ed8d1a557c",
        "part": "whole"
       },
       "id": "90449ea6-5afc-49c7-a0c0-f96385d5f3b1"
      }
     }
    },
    "6519229c-aad1-404e-bb0e-5f5e24e9166d": {
     "id": "6519229c-aad1-404e-bb0e-5f5e24e9166d",
     "prev": "22e9b66f-fd2e-42df-99cd-e4e0f21ad779",
     "regions": {
      "06daaf59-4da8-42e6-9c06-ee62a11f130d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "61f02149-01e2-4d54-9bd1-d7dd846badcc",
        "part": "whole"
       },
       "id": "06daaf59-4da8-42e6-9c06-ee62a11f130d"
      }
     }
    },
    "651edad8-ab58-4682-a530-d5d52db42903": {
     "id": "651edad8-ab58-4682-a530-d5d52db42903",
     "prev": "24557e4b-ec5d-43f2-bf81-bab6bc0cef90",
     "regions": {
      "6b41e10a-85cb-4b62-9cb9-d945af1bfae9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7cd741bd-a4ab-4824-9dcd-3708cfbad4e3",
        "part": "whole"
       },
       "id": "6b41e10a-85cb-4b62-9cb9-d945af1bfae9"
      }
     }
    },
    "6e92a7c5-48a3-47c4-83a7-2f78b56827d5": {
     "id": "6e92a7c5-48a3-47c4-83a7-2f78b56827d5",
     "prev": "c7c0225d-9d5f-4edf-a823-f2285eee72cc",
     "regions": {
      "7629b6b1-7cee-4ec2-9d6d-52d8ea7c0253": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "5a74133a-56c5-4d91-b13b-33ab05d996ce",
        "part": "whole"
       },
       "id": "7629b6b1-7cee-4ec2-9d6d-52d8ea7c0253"
      }
     }
    },
    "96a74b97-5cea-4633-9068-6187a1db86f2": {
     "id": "96a74b97-5cea-4633-9068-6187a1db86f2",
     "prev": "651edad8-ab58-4682-a530-d5d52db42903",
     "regions": {
      "ffda6832-e8b3-4b95-b1cd-c5261967aed8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a32ecb3d-7126-45aa-b39c-f245fd0245a4",
        "part": "whole"
       },
       "id": "ffda6832-e8b3-4b95-b1cd-c5261967aed8"
      }
     }
    },
    "98714c80-02b2-40f2-a770-b91ce7c1f3fa": {
     "id": "98714c80-02b2-40f2-a770-b91ce7c1f3fa",
     "prev": "3c3beb2d-9d61-4d5a-8994-02de7df212c0",
     "regions": {
      "502d0bc7-0b3d-4eba-bce3-89606d3733c5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ce9a3de4-cd6b-4df8-bfb2-9e62e1243c7e",
        "part": "whole"
       },
       "id": "502d0bc7-0b3d-4eba-bce3-89606d3733c5"
      }
     }
    },
    "b0c0a833-6909-4699-9d26-99772e73cf0f": {
     "id": "b0c0a833-6909-4699-9d26-99772e73cf0f",
     "prev": "6e92a7c5-48a3-47c4-83a7-2f78b56827d5",
     "regions": {
      "0b493bb1-915b-485c-9ca4-d4c1254dd071": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "53036ea1-9525-4153-ba9b-11f2494d8696",
        "part": "whole"
       },
       "id": "0b493bb1-915b-485c-9ca4-d4c1254dd071"
      }
     }
    },
    "c7c0225d-9d5f-4edf-a823-f2285eee72cc": {
     "id": "c7c0225d-9d5f-4edf-a823-f2285eee72cc",
     "prev": "98714c80-02b2-40f2-a770-b91ce7c1f3fa",
     "regions": {
      "3dd8f6f9-e07c-45ed-80ed-3f63303ca108": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8751a1a2-8b04-4589-a932-4225e954220f",
        "part": "whole"
       },
       "id": "3dd8f6f9-e07c-45ed-80ed-3f63303ca108"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
